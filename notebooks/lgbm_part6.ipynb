{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "適切に動作するノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 2.3.0\n",
      "sklearn version: 0.22.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/endotakeru/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "# データ可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "print('lightgbm version:', lgb.__version__)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "print('sklearn version:', sklearn.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import MeCab\n",
    "tagger = MeCab.Tagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/train_data.csv')\n",
    "test = pd.read_csv('../data/raw/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↑のjsonファイルをnames.jsonで保存してある前提\n",
    "with open(\"columns.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "     d = json.load(f)\n",
    "        \n",
    "train = train.rename(columns=d)\n",
    "test = test.rename(columns=d)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pd.read_csv('../data/raw/published_land_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = {\"所在地コード\":\"市区町村コード\",\"建蔽率\":\"建ぺい率（％）\",\"容積率\":\"容積率（％）\",\"駅名\":\"最寄駅：名称\", \n",
    "        \"地積\":\"面積（㎡）\",\"市区町村名\":\"市区町村名\",'前面道路の幅員':'前面道路：幅員（ｍ）', \n",
    "        \"前面道路の方位区分\":\"前面道路：方位\",\"前面道路区分\":\"前面道路：種類\",\"形状区分\":\"土地の形状\",\n",
    "        \"用途区分\":\"都市計画\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pub.rename(columns=pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pub.rename(columns=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', '経度', '緯度', 'MunicipalityCode', 'Use', '連番', '年次', '前年所在地コード',\n",
       "       '前年用途', '前年連番', 'Municipality', '住居表示', '行政', 'Area', '利用の現況', '利用状況表示',\n",
       "       '建物構造', '施設', 'LandShape', '間口（比率）', '奥行（比率）', '階層（地上）', '階層（地下）',\n",
       "       'Classification', 'Direction', 'Breadth', '前面道路の駅前区分', '前面道路の舗装状況',\n",
       "       '側道区分', '側道方位区分', '交通施設との近接区分', '周辺の土地の利用の現況', 'NearestStation', '駅距離',\n",
       "       'CityPlanning', '防火区分', '都市計画区分', '森林区分', '公園区分', 'CoverageRatio',\n",
       "       'FloorAreaRatio', '共通地点区分', '選定年次ビット', 'Ｓ５８価格', 'Ｓ５９価格', 'Ｓ６０価格',\n",
       "       'Ｓ６１価格', 'Ｓ６２価格', 'Ｓ６３価格', 'Ｈ１価格', 'Ｈ２価格', 'Ｈ３価格', 'Ｈ４価格', 'Ｈ５価格',\n",
       "       'Ｈ６価格', 'Ｈ７価格', 'Ｈ８価格', 'Ｈ９価格', 'Ｈ１０価格', 'Ｈ１１価格', 'Ｈ１２価格', 'Ｈ１３価格',\n",
       "       'Ｈ１４価格', 'Ｈ１５価格', 'Ｈ１６価格', 'Ｈ１７価格', 'Ｈ１８価格', 'Ｈ１９価格', 'Ｈ２０価格', 'Ｈ２１価格',\n",
       "       'Ｈ２２価格', 'Ｈ２３価格', 'Ｈ２４価格', 'Ｈ２５価格', 'Ｈ２６価格', 'Ｈ２７価格', 'Ｈ２８価格', 'Ｈ２９価格',\n",
       "       'Ｈ３０価格', 'Ｈ３１価格', '属性移動Ｓ５９', '属性移動Ｓ６０', '属性移動Ｓ６１', '属性移動Ｓ６２', '属性移動Ｓ６３',\n",
       "       '属性移動Ｈ１', '属性移動Ｈ２', '属性移動Ｈ３', '属性移動Ｈ４', '属性移動Ｈ５', '属性移動Ｈ６', '属性移動Ｈ７',\n",
       "       '属性移動Ｈ８', '属性移動Ｈ９', '属性移動Ｈ１０', '属性移動Ｈ１１', '属性移動Ｈ１２', '属性移動Ｈ１３',\n",
       "       '属性移動Ｈ１４', '属性移動Ｈ１５'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub.columns[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不要なカラムを落とす "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_columns = ['id', 'Prefecture', 'Municipality', 'DistrictName']\n",
    "train = train.drop(delete_columns, axis=1)\n",
    "test = test.drop(delete_columns, axis=1)\n",
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(index=[48111, 76360])\n",
    "y = train['y']\n",
    "train = train.drop('y', axis=1)\n",
    "y[320210] = 4500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stationの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Near = data['NearestStation'].str.split('(', expand=True)\n",
    "data = data.drop('NearestStation', axis=1)\n",
    "data['NearestStation'] = Near[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['latitude', 'longitude','h31_price']\n",
    "\n",
    "data['NearestStation+MunicipalityCode'] = data['NearestStation'] + '+' + data['MunicipalityCode'].astype(str)\n",
    "\n",
    "for i in new_columns:\n",
    "    data[i] =data['NearestStation+MunicipalityCode']\n",
    "\n",
    "def get_mean(search, cat):\n",
    "        leng = search.shape[0]\n",
    "        sum = 0\n",
    "        for i in range(leng):\n",
    "            if search.iloc[i][cat] != 0:\n",
    "                sum += search.iloc[i][cat]\n",
    "        return sum/leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2120f6e53dca4fdcb034b1343fed4577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1138.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_columns = ['latitude', 'longitude','h31_price', 'h30_price', 'h29_price', 'h28_price', 'h27_price', 'SerialNumber']\n",
    "\n",
    "data['NearestStation+MunicipalityCode'] = data['NearestStation'] + '+' + data['MunicipalityCode'].astype(str)\n",
    "\n",
    "for i in new_columns:\n",
    "    data[i] =data['NearestStation+MunicipalityCode']\n",
    "\n",
    "def get_mean(search, cat):\n",
    "        leng = search.shape[0]\n",
    "        sum = 0\n",
    "        for i in range(leng):\n",
    "            if search.iloc[i][cat] != 0:\n",
    "                sum += search.iloc[i][cat]\n",
    "        return sum/leng\n",
    "\n",
    "for i in tqdm(data['NearestStation+MunicipalityCode'].unique()):\n",
    "    try:\n",
    "            ns, mc = i.split('+')\n",
    "            search = pub[pub['MunicipalityCode'] == int(mc)][pub['NearestStation'] == ns]\n",
    "            try:\n",
    "                data['latitude'] = data['latitude'].replace(i, get_mean(search, '緯度'))\n",
    "                data['longitude'] = data['longitude'].replace(i, get_mean(search, '経度'))\n",
    "                data['h31_price'] = data['h31_price'].replace(i, get_mean(search, 'Ｈ３１価格'))\n",
    "                data['h30_price'] = data['h30_price'].replace(i, get_mean(search, 'Ｈ３０価格'))\n",
    "                data['h29_price'] = data['h29_price'].replace(i, get_mean(search, 'Ｈ２９価格'))\n",
    "                data['h28_price'] = data['h28_price'].replace(i, get_mean(search, 'Ｈ２８価格'))\n",
    "                data['h27_price'] = data['h27_price'].replace(i, get_mean(search, 'Ｈ２７価格'))\n",
    "                \n",
    "                data['SerialNumber'] = data['SerialNumber'].replace(i, get_mean(search, '連番'))\n",
    "            except:\n",
    "                try:\n",
    "                    search = pub[pub['NearestStation'] == ns]\n",
    "                    data['latitude'] = data['latitude'].replace(i, get_mean(search, '緯度'))\n",
    "                    data['longitude'] = data['longitude'].replace(i, get_mean(search, '経度'))\n",
    "                    data['h31_price'] = data['h31_price'].replace(i, get_mean(search, 'Ｈ３１価格'))\n",
    "                    data['h30_price'] = data['h30_price'].replace(i, get_mean(search, 'Ｈ３０価格'))\n",
    "                    data['h29_price'] = data['h29_price'].replace(i, get_mean(search, 'Ｈ２９価格'))\n",
    "                    data['h28_price'] = data['h28_price'].replace(i, get_mean(search, 'Ｈ２８価格'))\n",
    "                    data['h27_price'] = data['h27_price'].replace(i, get_mean(search, 'Ｈ２７価格'))                    \n",
    "                    data['SerialNumber'] = data['SerialNumber'].replace(i, get_mean(search, '連番'))                    \n",
    "                except:\n",
    "                    data['latitude'] = data['latitude'].replace(i, np.nan)\n",
    "                    data['longitude'] = data['longitude'].replace(i, np.nan)\n",
    "                    data['h31_price'] = data['h31_price'].replace(i, np.nan) \n",
    "                    data['h30_price'] = data['h30_price'].replace(i, np.nan)\n",
    "                    data['h29_price'] = data['h29_price'].replace(i, np.nan)\n",
    "                    data['h28_price'] = data['h28_price'].replace(i, np.nan)\n",
    "                    data['h27_price'] = data['h27_price'].replace(i, np.nan)                    \n",
    "                    data['SerialNumber'] = data['SerialNumber'].replace(i, np.nan)                    \n",
    "    except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('NearestStation+MunicipalityCode', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['h31_price'] = data['h31_price'].replace(0, np.nan) \n",
    "data['h30_price'] = data['h30_price'].replace(0, np.nan)\n",
    "data['h29_price'] = data['h29_price'].replace(0, np.nan)\n",
    "data['h28_price'] = data['h28_price'].replace(0, np.nan)\n",
    "data['h27_price'] = data['h27_price'].replace(0, np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.DataFrame({'h31_price': data['h31_price'].values, 'h30_price': data['h30_price'].values, \n",
    "                         'h29_price': data['h29_price'].values, 'h28_price': data['h28_price'].values, \n",
    "                              'h27_price' : data['h27_price'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df['h31_27_mean'] = price_df.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df['31-28'] = price_df['h31_price'] - price_df['h28_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h31_price', 'h30_price', 'h29_price', 'h28_price', 'h27_price',\n",
       "       'h31_27_mean', '31-28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = price_df.drop(['h30_price', 'h29_price', 'h28_price', 'h27_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['h31_27_mean'] = price_df['h31_27_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['31-28'] = price_df['31-28']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値データの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_median(df, df_type):\n",
    "    dumy = df\n",
    "    dumy = dumy.dropna()\n",
    "    dumy = dumy.astype(df_type)\n",
    "    df = df.fillna(dumy.mean())\n",
    "    df = df.astype(df_type)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最寄駅：距離（分） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TimeToNearestStation'] = data['TimeToNearestStation'].replace('2H?', '120').replace('30分?60分', '45'). \\\n",
    "        replace('1H30?2H', '105').replace('1H?1H30', '75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['TimeToNearestStation'] = calc_mean_median(data['TimeToNearestStation'], np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 面積"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumy_area = data['Area'].replace('2000㎡以上', np.nan).replace('5000㎡以上', np.nan)\n",
    "dumy_area = dumy_area.dropna()\n",
    "dumy_area = dumy_area.astype(np.int64)\n",
    "# 2000以上5000以下の平均値を取得\n",
    "area_mean_2000_5000 = np.mean([i for i in dumy_area if i > 2000 and i < 5000])\n",
    "# 5000以上はないので5500で置換\n",
    "# 欠損値を埋めるための平均と中央値\n",
    "dim_mean = dumy_area.mean()\n",
    "dim_median = dumy_area.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Area'] = data['Area'].replace('2000㎡以上',  area_mean_2000_5000).replace('5000㎡以上', 5500)\n",
    "data['Area'] =  data['Area'].fillna(dim_mean)  \n",
    "data['Area'] = data['Area'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 間口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Frontage'] = data['Frontage'].replace('50.0m以上', '60.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Frontage'] =   calc_mean_median(data['Frontage'], np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 延床面積（㎡）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalFloorArea'] = data['TotalFloorArea'].replace('2000㎡以上', '2500').replace( '10m^2未満', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalFloorArea'] =  calc_mean_median(data['TotalFloorArea'], np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 築年数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiku_columns = ['昭和59年', '平成15年', '平成24年', '昭和61年', '平成11年', '昭和60年', '平成19年',\n",
    "       '平成10年', '昭和57年', '昭和45年', '昭和47年', '昭和43年', '昭和64年', '平成25年',\n",
    "       '平成16年', '平成9年', '平成5年', '昭和51年', '平成13年', '昭和52年', '昭和55年',\n",
    "       '昭和54年', '平成2年', '平成21年', '平成22年', '平成18年', '平成14年', '平成6年',\n",
    "       '平成17年', '昭和62年', '平成12年', '昭和38年', '昭和41年', '昭和48年', '平成20年',\n",
    "       '昭和53年', '昭和49年', '平成26年', '昭和58年', '昭和56年', '昭和35年', '昭和50年',\n",
    "       '昭和37年', '平成23年', '平成7年', '平成3年', '昭和63年', '戦前', '平成29年', '昭和36年',\n",
    "       '平成28年', '昭和39年', '平成4年', '平成27年', '昭和42年', '昭和31年', '平成30年',\n",
    "       '昭和44年', '昭和29年', '平成8年', '昭和27年', '昭和46年', '昭和30年', '昭和33年',\n",
    "       '昭和32年', '昭和40年', '昭和26年', '昭和34年', '昭和25年', '昭和28年', '昭和22年',\n",
    "       '昭和24年', '昭和23年', '昭和21年', '平成31年']\n",
    "\n",
    "for i in tiku_columns:\n",
    "    if '平成' in i:\n",
    "        year = int(i.replace('年', '').replace('平成', '')) +2000-12\n",
    "        data['BuildingYear'] = data['BuildingYear'].replace(i, year)\n",
    "    if '昭和' in i:\n",
    "        year = int(i.replace('年', '').replace('昭和', '')) + 1925\n",
    "        data['BuildingYear'] = data['BuildingYear'].replace(i, year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1984, 2003, 2012, 1986, 1999, 1985, 2007, 1998, nan, 1982, 1970,\n",
       "       1972, 1968, 1989, 2013, 2004, 1997, 1993, 1976, 2001, 1977, 1980,\n",
       "       1979, 1990, 2009, 2010, 2006, 2002, 1994, 2005, 1987, 2000, 1963,\n",
       "       1966, 1973, 2008, 1978, 1974, 2014, 1983, 1981, 1960, 1975, 1962,\n",
       "       2011, 1995, 1991, 1988, '戦前', 2017, 1961, 2016, 1964, 1992, 2015,\n",
       "       1967, 1956, 2018, 1969, 1954, 1996, 1952, 1971, 1955, 1958, 1957,\n",
       "       1965, 1951, 1959, 1950, 1953, 1947, 1949, 1948, 1946, 2019],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['BuildingYear'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BuildingYear'] = data['BuildingYear'].replace('戦前', 1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BuildingYear'] =  calc_mean_median(data['BuildingYear'], np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BuildingYear'] = data['BuildingYear'] -1900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前面道路：幅員（ｍ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Breadth']=  calc_mean_median(data['Breadth'], np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  建ぺい率（％) 容積率（％） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CoverageRatio']=  calc_mean_median(data['CoverageRatio'], np.float64)\n",
    "data['FloorAreaRatio']=  calc_mean_median(data['FloorAreaRatio'], np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取引時点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torihiki_columns = data['Period'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(sorted(torihiki_columns)):\n",
    "    data['Period'] =  data['Period'].replace(value, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カテゴリーデータの整形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最寄駅：名称 - labelエンコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 間取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['L'] = data['FloorPlan'].map(lambda x: 1 if 'Ｌ' in str(x) else 0)\n",
    "data['D'] = data['FloorPlan'].map(lambda x: 1 if 'Ｄ' in str(x) else 0)\n",
    "data['K'] = data['FloorPlan'].map(lambda x: 1 if 'Ｋ' in str(x) else 0)\n",
    "data['S'] = data['FloorPlan'].map(lambda x: 1 if 'Ｓ' in str(x) else 0)\n",
    "data['R'] = data['FloorPlan'].map(lambda x: 1 if 'Ｒ' in str(x) else 0)\n",
    "data['Maisonette'] = data['FloorPlan'].map(lambda x: 1 if 'メゾネット' in str(x) else 0)\n",
    "data['OpenFloor'] = data['FloorPlan'].map(lambda x: 1 if 'オープンフロア' in str(x) else 0)\n",
    "data['Studio'] = data['FloorPlan'].map(lambda x: 1 if 'スタジオ' in str(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dummy =data['Use'].fillna('missing')\n",
    "use_dummy=  use_dummy.str.replace('共同住宅', '共同')\n",
    "for i in use_dummy.unique():\n",
    "    new_use = ''\n",
    "    if '住宅' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'\n",
    "    new_use += ','\n",
    "    if '事務所' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '店舗' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if 'その他' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '倉庫' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '駐車場' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '工場' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '共同' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    new_use += ','\n",
    "    if '作業場' in i:\n",
    "        new_use += '1'\n",
    "    else:\n",
    "        new_use += '0'        \n",
    "    use_dummy = use_dummy.replace(i, new_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use = use_dummy.str.split(',', expand=True)\n",
    "use_columns={0: 'Housing', 1: 'office', 2: 'store', 3: 'other_use', 4: 'Warehouse', 5: 'parking', 6: 'plant', 7: 'shareHouse', 8: 'Workshop'}\n",
    "data_use = data_use.rename(columns=use_columns)\n",
    "for i in data_use.columns:\n",
    "    data_use[i] = data_use[i].astype(np.int64)\n",
    "for i in data_use.columns:\n",
    "    data[i] = data_use[i]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウント数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Type', 'Region', 'NearestStation', 'FloorPlan','LandShape', 'Structure', 'Use', 'Purpose', 'Direction', \\\n",
    "         'Classification', 'CityPlanning', 'Renovation', 'Remarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_features:\n",
    "    data[c] =  data[c].fillna('missing') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for c in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[c])\n",
    "    data[c] = le.transform(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['longitude'] = data['longitude'] - 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['latitude'] = data['latitude'] -120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cols = ['h31_price','h30_price','h29_price','h28_price', 'h27_price', 'h31_27_mean']   \n",
    "for i in price_cols:\n",
    "    data[i] = data[i] /1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['h29_price','h28_price', 'h27_price'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:len(train)]\n",
    "test = data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352855\n",
      "352855\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['OpenFloor', 'Workshop', 'D', 'S', 'Studio', 'Maisonette', 'K', 'R']\n",
    "train = train.drop(drop_columns, axis=1)\n",
    "test = test.drop(drop_columns, axis=1)\n",
    "# highのtrainに幅を持たせるのは多分正解\n",
    "train_high = train.query('MunicipalityCode < 13150')\n",
    "train_low = train.query('(MunicipalityCode < 13150 and Area < 600) or MunicipalityCode > 13150')\n",
    "train_high_y = train_high['y']\n",
    "train_high = train_high.drop('y', axis=1)\n",
    "\n",
    "train_low_y = train_low['y']\n",
    "train_low = train_low.drop('y', axis=1)\n",
    "\n",
    "test = test.reset_index()\n",
    "\n",
    "# 800のほうがいいかもしれない\n",
    "test_high = test.query('MunicipalityCode < 13150 and Area >= 2200')\n",
    "test_low = test.query('(MunicipalityCode < 13150 and Area < 2200) or MunicipalityCode > 13150')\n",
    "\n",
    "test_high_data = test_high.drop('index', axis=1)\n",
    "test_low_data = test_low.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's mape: 1.3694\tvalid_1's mape: 1.37107\n",
      "[400]\ttraining's mape: 1.18655\tvalid_1's mape: 1.18746\n",
      "[600]\ttraining's mape: 1.03768\tvalid_1's mape: 1.03803\n",
      "[800]\ttraining's mape: 0.914824\tvalid_1's mape: 0.915126\n",
      "[1000]\ttraining's mape: 0.812328\tvalid_1's mape: 0.812672\n",
      "[1200]\ttraining's mape: 0.727157\tvalid_1's mape: 0.727548\n",
      "[1400]\ttraining's mape: 0.657173\tvalid_1's mape: 0.657917\n",
      "[1600]\ttraining's mape: 0.599412\tvalid_1's mape: 0.600499\n",
      "[1800]\ttraining's mape: 0.552306\tvalid_1's mape: 0.554076\n",
      "[2000]\ttraining's mape: 0.512842\tvalid_1's mape: 0.515097\n",
      "[2200]\ttraining's mape: 0.480137\tvalid_1's mape: 0.482862\n",
      "[2400]\ttraining's mape: 0.452723\tvalid_1's mape: 0.455925\n",
      "[2600]\ttraining's mape: 0.429824\tvalid_1's mape: 0.433518\n",
      "[2800]\ttraining's mape: 0.410399\tvalid_1's mape: 0.414655\n",
      "[3000]\ttraining's mape: 0.393928\tvalid_1's mape: 0.398724\n",
      "[3200]\ttraining's mape: 0.379836\tvalid_1's mape: 0.385247\n",
      "[3400]\ttraining's mape: 0.367594\tvalid_1's mape: 0.373615\n",
      "[3600]\ttraining's mape: 0.357018\tvalid_1's mape: 0.363624\n",
      "[3800]\ttraining's mape: 0.347782\tvalid_1's mape: 0.355003\n",
      "[4000]\ttraining's mape: 0.339674\tvalid_1's mape: 0.3475\n",
      "[4200]\ttraining's mape: 0.332615\tvalid_1's mape: 0.341048\n",
      "[4400]\ttraining's mape: 0.326336\tvalid_1's mape: 0.335439\n",
      "[4600]\ttraining's mape: 0.320809\tvalid_1's mape: 0.330531\n",
      "[4800]\ttraining's mape: 0.315817\tvalid_1's mape: 0.326177\n",
      "[5000]\ttraining's mape: 0.311373\tvalid_1's mape: 0.322339\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.311373\tvalid_1's mape: 0.322339\n",
      "87242 87242 87242\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's mape: 1.3593\tvalid_1's mape: 1.34865\n",
      "[400]\ttraining's mape: 1.17769\tvalid_1's mape: 1.16818\n",
      "[600]\ttraining's mape: 1.02956\tvalid_1's mape: 1.0214\n",
      "[800]\ttraining's mape: 0.908159\tvalid_1's mape: 0.901145\n",
      "[1000]\ttraining's mape: 0.807076\tvalid_1's mape: 0.801162\n",
      "[1200]\ttraining's mape: 0.723064\tvalid_1's mape: 0.718157\n",
      "[1400]\ttraining's mape: 0.653801\tvalid_1's mape: 0.649758\n",
      "[1600]\ttraining's mape: 0.596502\tvalid_1's mape: 0.593229\n",
      "[1800]\ttraining's mape: 0.549802\tvalid_1's mape: 0.547376\n",
      "[2000]\ttraining's mape: 0.510605\tvalid_1's mape: 0.509008\n",
      "[2200]\ttraining's mape: 0.478263\tvalid_1's mape: 0.477496\n",
      "[2400]\ttraining's mape: 0.451093\tvalid_1's mape: 0.451128\n",
      "[2600]\ttraining's mape: 0.428469\tvalid_1's mape: 0.429264\n",
      "[2800]\ttraining's mape: 0.409122\tvalid_1's mape: 0.410664\n",
      "[3000]\ttraining's mape: 0.392701\tvalid_1's mape: 0.394888\n",
      "[3200]\ttraining's mape: 0.378706\tvalid_1's mape: 0.381377\n",
      "[3400]\ttraining's mape: 0.366437\tvalid_1's mape: 0.369547\n",
      "[3600]\ttraining's mape: 0.35577\tvalid_1's mape: 0.35934\n",
      "[3800]\ttraining's mape: 0.346542\tvalid_1's mape: 0.350595\n",
      "[4000]\ttraining's mape: 0.338604\tvalid_1's mape: 0.343042\n",
      "[4200]\ttraining's mape: 0.331713\tvalid_1's mape: 0.336533\n",
      "[4400]\ttraining's mape: 0.325684\tvalid_1's mape: 0.330992\n",
      "[4600]\ttraining's mape: 0.320219\tvalid_1's mape: 0.325977\n",
      "[4800]\ttraining's mape: 0.315401\tvalid_1's mape: 0.321557\n",
      "[5000]\ttraining's mape: 0.311108\tvalid_1's mape: 0.317688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.311108\tvalid_1's mape: 0.317688\n",
      "87242 87242 87242\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's mape: 1.36134\tvalid_1's mape: 1.36167\n",
      "[400]\ttraining's mape: 1.17929\tvalid_1's mape: 1.1808\n",
      "[600]\ttraining's mape: 1.03087\tvalid_1's mape: 1.03374\n",
      "[800]\ttraining's mape: 0.908553\tvalid_1's mape: 0.912812\n",
      "[1000]\ttraining's mape: 0.80657\tvalid_1's mape: 0.812056\n",
      "[1200]\ttraining's mape: 0.721941\tvalid_1's mape: 0.728749\n",
      "[1400]\ttraining's mape: 0.652671\tvalid_1's mape: 0.660635\n",
      "[1600]\ttraining's mape: 0.595371\tvalid_1's mape: 0.604503\n",
      "[1800]\ttraining's mape: 0.548662\tvalid_1's mape: 0.558906\n",
      "[2000]\ttraining's mape: 0.509318\tvalid_1's mape: 0.520518\n",
      "[2200]\ttraining's mape: 0.476702\tvalid_1's mape: 0.488915\n",
      "[2400]\ttraining's mape: 0.4492\tvalid_1's mape: 0.462416\n",
      "[2600]\ttraining's mape: 0.426291\tvalid_1's mape: 0.440482\n",
      "[2800]\ttraining's mape: 0.406845\tvalid_1's mape: 0.421783\n",
      "[3000]\ttraining's mape: 0.390383\tvalid_1's mape: 0.406181\n",
      "[3200]\ttraining's mape: 0.376345\tvalid_1's mape: 0.392928\n",
      "[3400]\ttraining's mape: 0.364166\tvalid_1's mape: 0.381605\n",
      "[3600]\ttraining's mape: 0.353675\tvalid_1's mape: 0.372129\n",
      "[3800]\ttraining's mape: 0.344384\tvalid_1's mape: 0.363779\n",
      "[4000]\ttraining's mape: 0.33626\tvalid_1's mape: 0.356462\n",
      "[4200]\ttraining's mape: 0.329211\tvalid_1's mape: 0.350207\n",
      "[4400]\ttraining's mape: 0.323003\tvalid_1's mape: 0.344708\n",
      "[4600]\ttraining's mape: 0.31751\tvalid_1's mape: 0.339911\n",
      "[4800]\ttraining's mape: 0.312505\tvalid_1's mape: 0.335564\n",
      "[5000]\ttraining's mape: 0.308108\tvalid_1's mape: 0.33182\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.308108\tvalid_1's mape: 0.33182\n",
      "87241 87241 87241\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's mape: 1.35249\tvalid_1's mape: 1.36352\n",
      "[400]\ttraining's mape: 1.17186\tvalid_1's mape: 1.18475\n",
      "[600]\ttraining's mape: 1.02463\tvalid_1's mape: 1.03898\n",
      "[800]\ttraining's mape: 0.903522\tvalid_1's mape: 0.919025\n",
      "[1000]\ttraining's mape: 0.802468\tvalid_1's mape: 0.819044\n",
      "[1200]\ttraining's mape: 0.718773\tvalid_1's mape: 0.736162\n",
      "[1400]\ttraining's mape: 0.650183\tvalid_1's mape: 0.668291\n",
      "[1600]\ttraining's mape: 0.593271\tvalid_1's mape: 0.611847\n",
      "[1800]\ttraining's mape: 0.546767\tvalid_1's mape: 0.565723\n",
      "[2000]\ttraining's mape: 0.50785\tvalid_1's mape: 0.52713\n",
      "[2200]\ttraining's mape: 0.475489\tvalid_1's mape: 0.495139\n",
      "[2400]\ttraining's mape: 0.448433\tvalid_1's mape: 0.468273\n",
      "[2600]\ttraining's mape: 0.425838\tvalid_1's mape: 0.445954\n",
      "[2800]\ttraining's mape: 0.406677\tvalid_1's mape: 0.426918\n",
      "[3000]\ttraining's mape: 0.390606\tvalid_1's mape: 0.41101\n",
      "[3200]\ttraining's mape: 0.376785\tvalid_1's mape: 0.397365\n",
      "[3400]\ttraining's mape: 0.364889\tvalid_1's mape: 0.385565\n",
      "[3600]\ttraining's mape: 0.354563\tvalid_1's mape: 0.375372\n",
      "[3800]\ttraining's mape: 0.345577\tvalid_1's mape: 0.366627\n",
      "[4000]\ttraining's mape: 0.337683\tvalid_1's mape: 0.358916\n",
      "[4200]\ttraining's mape: 0.330757\tvalid_1's mape: 0.352221\n",
      "[4400]\ttraining's mape: 0.32472\tvalid_1's mape: 0.346618\n",
      "[4600]\ttraining's mape: 0.319419\tvalid_1's mape: 0.341687\n",
      "[4800]\ttraining's mape: 0.314568\tvalid_1's mape: 0.337261\n",
      "[5000]\ttraining's mape: 0.310165\tvalid_1's mape: 0.333322\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.310165\tvalid_1's mape: 0.333322\n",
      "87241 87241 87241\n",
      "RMSE: 73.16353686070322\n"
     ]
    }
   ],
   "source": [
    "### lowの予測\n",
    "scores = []\n",
    "y_low_pred = np.zeros(test_low_data.shape[0])\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_low):\n",
    "    tr_x, va_x = train_low.iloc[tr_idx], train_low.iloc[va_idx]\n",
    "    tr_y, va_y = train_low_y.iloc[tr_idx], train_low_y.iloc[va_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(tr_x, tr_y)\n",
    "    valid_data = lgb.Dataset(va_x, va_y)\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mape',\n",
    "        'learning_rate': 0.001,\n",
    "        'max_depth': -1,\n",
    "        'num_leaves': 255,\n",
    "        'max_bin': 255,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'nthread': -1,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': -1,\n",
    "        'seed': 1\n",
    "#         'seed': random.randint(1, 100),\n",
    "    }\n",
    "    model = lgb.train(params, train_data, valid_sets=[train_data, valid_data],\n",
    "                      num_boost_round=5000, early_stopping_rounds=200,\n",
    "                      verbose_eval=200)\n",
    "\n",
    "    y_val_pred = model.predict(va_x)\n",
    "    print(len(va_x), len(y_val_pred), len(va_y))\n",
    "    val_score = np.sqrt(mean_squared_error(va_y, y_val_pred))\n",
    "    y_low_pred  += model.predict(test_low_data, num_iteration=model.best_iteration)\n",
    "    scores.append(val_score)\n",
    "\n",
    "print('RMSE:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's mape: 1.77796\tvalid_1's mape: 1.76744\n",
      "[400]\ttraining's mape: 1.51\tvalid_1's mape: 1.5034\n",
      "[600]\ttraining's mape: 1.29204\tvalid_1's mape: 1.28918\n",
      "[800]\ttraining's mape: 1.11387\tvalid_1's mape: 1.11435\n",
      "[1000]\ttraining's mape: 0.966369\tvalid_1's mape: 0.969659\n",
      "[1200]\ttraining's mape: 0.844387\tvalid_1's mape: 0.850026\n",
      "[1400]\ttraining's mape: 0.745001\tvalid_1's mape: 0.752547\n",
      "[1600]\ttraining's mape: 0.663262\tvalid_1's mape: 0.672312\n",
      "[1800]\ttraining's mape: 0.597205\tvalid_1's mape: 0.607546\n",
      "[2000]\ttraining's mape: 0.542478\tvalid_1's mape: 0.553873\n",
      "[2200]\ttraining's mape: 0.497541\tvalid_1's mape: 0.509854\n",
      "[2400]\ttraining's mape: 0.460608\tvalid_1's mape: 0.473583\n",
      "[2600]\ttraining's mape: 0.430516\tvalid_1's mape: 0.444136\n",
      "[2800]\ttraining's mape: 0.405347\tvalid_1's mape: 0.419433\n",
      "[3000]\ttraining's mape: 0.384744\tvalid_1's mape: 0.399441\n",
      "[3200]\ttraining's mape: 0.367741\tvalid_1's mape: 0.382915\n",
      "[3400]\ttraining's mape: 0.353535\tvalid_1's mape: 0.369225\n",
      "[3600]\ttraining's mape: 0.341383\tvalid_1's mape: 0.357615\n",
      "[3800]\ttraining's mape: 0.33099\tvalid_1's mape: 0.347844\n",
      "[4000]\ttraining's mape: 0.322264\tvalid_1's mape: 0.339775\n",
      "[4200]\ttraining's mape: 0.314914\tvalid_1's mape: 0.333157\n",
      "[4400]\ttraining's mape: 0.308484\tvalid_1's mape: 0.327286\n",
      "[4600]\ttraining's mape: 0.30284\tvalid_1's mape: 0.322306\n",
      "[4800]\ttraining's mape: 0.29789\tvalid_1's mape: 0.317882\n",
      "[5000]\ttraining's mape: 0.293531\tvalid_1's mape: 0.313975\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.293531\tvalid_1's mape: 0.313975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's mape: 1.79318\tvalid_1's mape: 1.81153\n",
      "[400]\ttraining's mape: 1.52246\tvalid_1's mape: 1.54032\n",
      "[600]\ttraining's mape: 1.3024\tvalid_1's mape: 1.32007\n",
      "[800]\ttraining's mape: 1.12244\tvalid_1's mape: 1.1402\n",
      "[1000]\ttraining's mape: 0.97389\tvalid_1's mape: 0.991814\n",
      "[1200]\ttraining's mape: 0.850977\tvalid_1's mape: 0.868965\n",
      "[1400]\ttraining's mape: 0.750527\tvalid_1's mape: 0.768691\n",
      "[1600]\ttraining's mape: 0.66793\tvalid_1's mape: 0.686374\n",
      "[1800]\ttraining's mape: 0.601032\tvalid_1's mape: 0.619882\n",
      "[2000]\ttraining's mape: 0.545574\tvalid_1's mape: 0.5648\n",
      "[2200]\ttraining's mape: 0.500276\tvalid_1's mape: 0.519915\n",
      "[2400]\ttraining's mape: 0.462772\tvalid_1's mape: 0.482846\n",
      "[2600]\ttraining's mape: 0.432354\tvalid_1's mape: 0.452834\n",
      "[2800]\ttraining's mape: 0.406963\tvalid_1's mape: 0.427806\n",
      "[3000]\ttraining's mape: 0.386283\tvalid_1's mape: 0.407462\n",
      "[3200]\ttraining's mape: 0.36911\tvalid_1's mape: 0.390626\n",
      "[3400]\ttraining's mape: 0.354703\tvalid_1's mape: 0.376606\n",
      "[3600]\ttraining's mape: 0.34259\tvalid_1's mape: 0.364883\n",
      "[3800]\ttraining's mape: 0.332354\tvalid_1's mape: 0.354993\n",
      "[4000]\ttraining's mape: 0.323603\tvalid_1's mape: 0.346518\n",
      "[4200]\ttraining's mape: 0.316251\tvalid_1's mape: 0.339425\n",
      "[4400]\ttraining's mape: 0.309783\tvalid_1's mape: 0.333174\n",
      "[4600]\ttraining's mape: 0.304248\tvalid_1's mape: 0.327864\n",
      "[4800]\ttraining's mape: 0.299421\tvalid_1's mape: 0.323258\n",
      "[5000]\ttraining's mape: 0.295197\tvalid_1's mape: 0.319241\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.295197\tvalid_1's mape: 0.319241\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's mape: 1.77686\tvalid_1's mape: 1.78053\n",
      "[400]\ttraining's mape: 1.50925\tvalid_1's mape: 1.51233\n",
      "[600]\ttraining's mape: 1.29179\tvalid_1's mape: 1.29465\n",
      "[800]\ttraining's mape: 1.11395\tvalid_1's mape: 1.11694\n",
      "[1000]\ttraining's mape: 0.967044\tvalid_1's mape: 0.970239\n",
      "[1200]\ttraining's mape: 0.845454\tvalid_1's mape: 0.848995\n",
      "[1400]\ttraining's mape: 0.746302\tvalid_1's mape: 0.750169\n",
      "[1600]\ttraining's mape: 0.664893\tvalid_1's mape: 0.669259\n",
      "[1800]\ttraining's mape: 0.599012\tvalid_1's mape: 0.60386\n",
      "[2000]\ttraining's mape: 0.544304\tvalid_1's mape: 0.549648\n",
      "[2200]\ttraining's mape: 0.499488\tvalid_1's mape: 0.505379\n",
      "[2400]\ttraining's mape: 0.462551\tvalid_1's mape: 0.468975\n",
      "[2600]\ttraining's mape: 0.432338\tvalid_1's mape: 0.439347\n",
      "[2800]\ttraining's mape: 0.407181\tvalid_1's mape: 0.414774\n",
      "[3000]\ttraining's mape: 0.38654\tvalid_1's mape: 0.394682\n",
      "[3200]\ttraining's mape: 0.369493\tvalid_1's mape: 0.378127\n",
      "[3400]\ttraining's mape: 0.355209\tvalid_1's mape: 0.364263\n",
      "[3600]\ttraining's mape: 0.343228\tvalid_1's mape: 0.3527\n",
      "[3800]\ttraining's mape: 0.332945\tvalid_1's mape: 0.342773\n",
      "[4000]\ttraining's mape: 0.324381\tvalid_1's mape: 0.334514\n",
      "[4200]\ttraining's mape: 0.316949\tvalid_1's mape: 0.327347\n",
      "[4400]\ttraining's mape: 0.310592\tvalid_1's mape: 0.321268\n",
      "[4600]\ttraining's mape: 0.305075\tvalid_1's mape: 0.315991\n",
      "[4800]\ttraining's mape: 0.30032\tvalid_1's mape: 0.311539\n",
      "[5000]\ttraining's mape: 0.296032\tvalid_1's mape: 0.307599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.296032\tvalid_1's mape: 0.307599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's mape: 1.7589\tvalid_1's mape: 1.74878\n",
      "[400]\ttraining's mape: 1.4953\tvalid_1's mape: 1.48507\n",
      "[600]\ttraining's mape: 1.28106\tvalid_1's mape: 1.27112\n",
      "[800]\ttraining's mape: 1.10617\tvalid_1's mape: 1.09666\n",
      "[1000]\ttraining's mape: 0.961252\tvalid_1's mape: 0.952216\n",
      "[1200]\ttraining's mape: 0.841445\tvalid_1's mape: 0.832903\n",
      "[1400]\ttraining's mape: 0.743426\tvalid_1's mape: 0.735476\n",
      "[1600]\ttraining's mape: 0.663016\tvalid_1's mape: 0.655625\n",
      "[1800]\ttraining's mape: 0.597963\tvalid_1's mape: 0.591072\n",
      "[2000]\ttraining's mape: 0.544047\tvalid_1's mape: 0.537679\n",
      "[2200]\ttraining's mape: 0.499799\tvalid_1's mape: 0.49395\n",
      "[2400]\ttraining's mape: 0.463157\tvalid_1's mape: 0.457891\n",
      "[2600]\ttraining's mape: 0.433509\tvalid_1's mape: 0.428805\n",
      "[2800]\ttraining's mape: 0.408624\tvalid_1's mape: 0.404489\n",
      "[3000]\ttraining's mape: 0.388316\tvalid_1's mape: 0.384585\n",
      "[3200]\ttraining's mape: 0.371384\tvalid_1's mape: 0.368143\n",
      "[3400]\ttraining's mape: 0.357132\tvalid_1's mape: 0.354338\n",
      "[3600]\ttraining's mape: 0.345088\tvalid_1's mape: 0.342651\n",
      "[3800]\ttraining's mape: 0.335066\tvalid_1's mape: 0.333025\n",
      "[4000]\ttraining's mape: 0.326386\tvalid_1's mape: 0.324779\n",
      "[4200]\ttraining's mape: 0.31909\tvalid_1's mape: 0.317868\n",
      "[4400]\ttraining's mape: 0.312738\tvalid_1's mape: 0.311973\n",
      "[4600]\ttraining's mape: 0.307225\tvalid_1's mape: 0.306905\n",
      "[4800]\ttraining's mape: 0.302424\tvalid_1's mape: 0.302446\n",
      "[5000]\ttraining's mape: 0.298081\tvalid_1's mape: 0.298484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttraining's mape: 0.298081\tvalid_1's mape: 0.298484\n",
      "RMSE: 198.5112981061596\n"
     ]
    }
   ],
   "source": [
    "### highの予測\n",
    "scores = []\n",
    "y_high_pred = np.zeros(test_high_data.shape[0])\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "for tr_idx, va_idx in kf.split(train_high):\n",
    "    tr_x, va_x = train_high.iloc[tr_idx], train_high.iloc[va_idx]\n",
    "    tr_y, va_y = train_high_y.iloc[tr_idx], train_high_y.iloc[va_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(tr_x, tr_y)\n",
    "    valid_data = lgb.Dataset(va_x, va_y)\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mape',\n",
    "        'learning_rate': 0.001,\n",
    "        'max_depth': -1,\n",
    "        'num_leaves': 200,\n",
    "        'max_bin': 255,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'nthread': -1,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': -1,\n",
    "        'seed': 1\n",
    "#         'seed': random.randint(1, 100),\n",
    "    }\n",
    "    model = lgb.train(params, train_data, valid_sets=[train_data, valid_data],\n",
    "                      num_boost_round=5000, early_stopping_rounds=100,\n",
    "                      verbose_eval=200)\n",
    "\n",
    "    y_val_pred = model.predict(va_x)\n",
    "    val_score = np.sqrt(mean_squared_error(va_y, y_val_pred*1.03))\n",
    "    y_high_pred  += model.predict(test_high_data, num_iteration=model.best_iteration)\n",
    "    scores.append(val_score)\n",
    "\n",
    "print('RMSE:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>240.702939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>474.624123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-45.584070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>94.800827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>146.922922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.370785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15168.050016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  34816.000000\n",
       "mean     240.702939\n",
       "std      474.624123\n",
       "min      -45.584070\n",
       "25%       94.800827\n",
       "50%      146.922922\n",
       "75%      218.370785\n",
       "max    15168.050016"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_low_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10019.169594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9218.684459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2811.187220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4877.817614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6872.930366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10584.470095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39720.328352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count     28.000000\n",
       "mean   10019.169594\n",
       "std     9218.684459\n",
       "min     2811.187220\n",
       "25%     4877.817614\n",
       "50%     6872.930366\n",
       "75%    10584.470095\n",
       "max    39720.328352"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_high_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_high['pred'] = y_high_pred\n",
    "test_low['pred'] = y_low_pred\n",
    "test = pd.concat((test_high, test_low))\n",
    "test = test.sort_values('index')\n",
    "y_pred  = test['pred']\n",
    "y_pred = np.round(y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34776</th>\n",
       "      <td>34777</td>\n",
       "      <td>-45.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34806</th>\n",
       "      <td>34807</td>\n",
       "      <td>-42.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34817</th>\n",
       "      <td>34818</td>\n",
       "      <td>-41.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34818</th>\n",
       "      <td>34819</td>\n",
       "      <td>-15.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34820</th>\n",
       "      <td>34821</td>\n",
       "      <td>-29.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      y\n",
       "34776  34777 -45.58\n",
       "34806  34807 -42.94\n",
       "34817  34818 -41.92\n",
       "34818  34819 -15.77\n",
       "34820  34821 -29.33"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/raw/test_data.csv')\n",
    "sub = pd.DataFrame({'id': submit['id'], 'y': y_pred})\n",
    "sub.query('y < 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub[sub['y'] < 0]['id']:\n",
    "    sub['y'][i-1] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_lgbm_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34844.000000\n",
       "mean       248.565731\n",
       "std        606.396426\n",
       "min          0.000000\n",
       "25%         94.830000\n",
       "50%        147.010000\n",
       "75%        218.760000\n",
       "max      39720.330000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
